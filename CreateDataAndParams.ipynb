{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时候需要对加速度计数据添加重力。旋转矩阵添加欧拉角的噪声，加速度计也添加对应的噪声，增加泛化性能\n",
      "shape.pt: SMPL parameter(没什么关系)\n",
      " pose.pt: 24个关节姿态的轴角表示\n",
      "joint.pt: 24个关节相对位置\n",
      " tran.pt: 人物动作的绝对位置(与绝对位置结合可得真实位置)\n",
      " vrot.pt: 生成的陀螺数据(右脚尖，左脚尖，后腰)，实际上是姿态旋转矩阵，需要AHRS算出姿态\n",
      " vacc.pt: 生成的n系加速度计数据(右脚尖，左脚尖，后腰)，需要根据姿态旋转到n系东北天\n",
      "有用的关节：     11,     10,     8,     7,      5,     4,       2,       1\n",
      "    对应为： 右脚尖， 左脚尖；右脚踝，左脚踝；右膝盖，左膝盖；右大腿根，左大腿根\n",
      "##################################################\n",
      "Reading HumanEva\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f081df7309e4a01bb2fadf92d40f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MPI_HDM05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bd45bc26464a759db9f4fe82554f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SFU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10348c79bb234cd9947484c125f33afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MPI_mosh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53810dc0d1fe4cad8abd534263579d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Transitions_mocap\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ecf2a7ae0f4362b967f4b0e79fc7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SSM_synced\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe2dcd247d54e21bc0e7c187183d106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CMU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f2cb0977904d18bcdee195cae51d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TotalCapture\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac2b4d5b943472d856854967785a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Eyes_Japan_Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b81a401806145058d790ae23a52fcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading KIT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6903b633d63e4ae2a09acdeec3d63822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading BMLmovi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e904aa687bb844ccb678645a49a95ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading EKUT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53b0a015aaa4271ac7c0e63c737ec73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TCD_handMocap\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a496de65fa4572a64deb941d8b66b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ACCAD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4415337f148c4700b1d173a7c70363f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading BioMotionLab_NTroje\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84f9c8ff9dc4fb8abea24f54e2eb3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading BMLhandball\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59f45ccec744583b7e5e7a067db6b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MPI_Limits\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f73d8fbb0c4a23b5e8969a1824329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DFaust67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ee5614624846778e92dadabf4b7ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "AMASS dataset not found. Check config.py or comment the function process_amass()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTransPose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_amass, process_dipimu\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练时候需要对加速度计数据添加重力。旋转矩阵添加欧拉角的噪声，加速度计也添加对应的噪声，增加泛化性能\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mprocess_amass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# process_dipimu() \u001b[39;00m\n",
      "File \u001b[0;32m~/multi-imu/utils/TransPose/preprocess.py:94\u001b[0m, in \u001b[0;36mprocess_amass\u001b[0;34m(smooth_n)\u001b[0m\n\u001b[1;32m     87\u001b[0m         data_beta\u001b[38;5;241m.\u001b[39mappend(cdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m     88\u001b[0m         length\u001b[38;5;241m.\u001b[39mappend(cdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposes\u001b[39m\u001b[38;5;124m'\u001b[39m][::step]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_pose) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMASS dataset not found. Check config.py or comment the function process_amass()\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     95\u001b[0m length \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[1;32m     96\u001b[0m shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39masarray(data_beta, np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "\u001b[0;31mAssertionError\u001b[0m: AMASS dataset not found. Check config.py or comment the function process_amass()"
     ]
    }
   ],
   "source": [
    "from utils.TransPose.preprocess import process_amass, process_dipimu\n",
    "\n",
    "print(\"训练时候需要对加速度计数据添加重力。旋转矩阵添加欧拉角的噪声，加速度计也添加对应的噪声，增加泛化性能\")\n",
    "process_amass()\n",
    "# process_dipimu() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, argparse\n",
    "from utils.wmx_tools import create_parser\n",
    "\n",
    "# 导入创建的yaml文件\n",
    "with open('./configs/train_params_LSTM.yaml', 'r') as f:\n",
    "    # yml = yaml.load(f, yaml.FullLoader)\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.set_defaults(**yaml.load(f, yaml.FullLoader))\n",
    "    args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56474/3052335532.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_pose = torch.load(os.path.join(paths.amass_dir, 'pose.pt'))      # 24个关节的轴角表示\n",
      "/tmp/ipykernel_56474/3052335532.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_tran = torch.load(os.path.join(paths.amass_dir, 'tran.pt'))      # 人物动作的绝对位置\n",
      "/tmp/ipykernel_56474/3052335532.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_joint = torch.load(os.path.join(paths.amass_dir, 'joint.pt'))     # 24个关节相对位置\n",
      "/tmp/ipykernel_56474/3052335532.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_vrot = torch.load(os.path.join(paths.amass_dir, 'vrot.pt'))      # 生成的陀螺数据(实际上是姿态旋转矩阵，需要AHRS算出姿态)\n",
      "/tmp/ipykernel_56474/3052335532.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_vacc = torch.load(os.path.join(paths.amass_dir, 'vacc.pt'))      # 生成的加速度计数据\n",
      "/tmp/ipykernel_56474/3052335532.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  out_shape = torch.load(os.path.join(paths.amass_dir, 'shape.pt'))     # SMPL parameter(没什么关系)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_tran的形状为,torch.Size([1460, 3])\n",
      "out_joint的形状为,torch.Size([1677, 24, 3])\n",
      "out_vacc 样本数量: 1677\n",
      "第一个样本的加速度数据形状: torch.Size([1677, 3, 3])\n",
      "\n",
      "out_vrot 样本数量: 9124\n",
      "第一个样本的旋转数据形状: torch.Size([1677, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34de51d007314bc6ad60288e28fe1baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.wmx_tools import normalize_and_concat_X, normalize_and_concat_y\n",
    "import torch, os\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.TransPose.config import paths, joint_set, acc_scale, vel_scale\n",
    "\n",
    "out_pose = torch.load(os.path.join(paths.amass_dir, 'pose.pt'))      # 24个关节的轴角表示\n",
    "out_tran = torch.load(os.path.join(paths.amass_dir, 'tran.pt'))      # 人物动作的绝对位置\n",
    "out_joint = torch.load(os.path.join(paths.amass_dir, 'joint.pt'))     # 24个关节相对位置\n",
    "out_vrot = torch.load(os.path.join(paths.amass_dir, 'vrot.pt'))      # 生成的陀螺数据(实际上是姿态旋转矩阵，需要AHRS算出姿态)\n",
    "out_vacc = torch.load(os.path.join(paths.amass_dir, 'vacc.pt'))      # 生成的加速度计数据\n",
    "out_shape = torch.load(os.path.join(paths.amass_dir, 'shape.pt'))     # SMPL parameter(没什么关系)\n",
    "\n",
    "print(f\"out_tran的形状为,{out_tran[1].shape}\")\n",
    "print(f\"out_joint的形状为,{out_joint[0].shape}\")\n",
    "# 检查列表长度和第一个元素的形状\n",
    "print(f\"out_vacc 样本数量: {len(out_vacc[0])}\")\n",
    "if len(out_vacc) > 0:\n",
    "    print(f\"第一个样本的加速度数据形状: {out_vacc[0].shape}\")\n",
    "\n",
    "print(f\"\\nout_vrot 样本数量: {len(out_vrot)}\")\n",
    "if len(out_vrot) > 0:\n",
    "    print(f\"第一个样本的旋转数据形状: {out_vrot[0].shape}\")\n",
    "\n",
    "X, y = [], []\n",
    "velocity_list = []\n",
    "dataacc = []\n",
    "for i in tqdm(range(len(out_tran))):\n",
    "    #加速度数据标准化并归一化\n",
    "    if (out_vacc[i].shape[0] > 100):  #超过30个数据再归一化\n",
    "        X_tuple = normalize_and_concat_X(out_vacc[i] / acc_scale, out_vrot[i], False)\n",
    "        X.append(X_tuple)\n",
    "        # X.append(normalize_and_concat_X(out_vacc[i] / acc_scale, out_vrot[i], False))     \n",
    "        # y.append(normalize_and_concat_y(out_tran[i], out_pose[i], out_joint[i], out_vrot[i], out_shape[i]))\n",
    "        y_tuple = normalize_and_concat_y(out_tran[i], out_pose[i], out_joint[i], out_vrot[i], out_shape[i])\n",
    "        y.append(y_tuple)\n",
    "        data =X_tuple\n",
    "        dataacc.append(data)\n",
    "        velocity = y_tuple[3]\n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=857857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8839\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "速度数据已保存至: velocity_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_velocity_to_csv(velocity_list, output_path=\"velocity_data.csv\"):\n",
    "    # 收集所有速度数据\n",
    "    all_velocity = []\n",
    "    for sample_idx, velocity_tensor in enumerate(velocity_list):\n",
    "        # 转换张量为numpy格式\n",
    "        velocity_np = velocity_tensor.cpu().numpy()  # 如果张量在GPU上\n",
    "        \n",
    "        # 确保形状为 [T, 3]（时间步长 x 速度分量）\n",
    "        if len(velocity_np.shape) == 1:\n",
    "            velocity_np = velocity_np.reshape(-1, 3)\n",
    "            \n",
    "        # 为每个时间步添加样本ID和时间步ID\n",
    "        for t in range(velocity_np.shape[0]):\n",
    "            all_velocity.append([\n",
    "                sample_idx,  # 样本ID\n",
    "                t,           # 时间步ID\n",
    "                velocity_np[t, 0],  # 速度X分量\n",
    "                velocity_np[t, 1],  # 速度Y分量\n",
    "                velocity_np[t, 2]   # 速度Z分量\n",
    "            ])\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        all_velocity,\n",
    "        columns=[\"SampleID\", \"Timestep\", \"Velocity_X\", \"Velocity_Y\", \"Velocity_Z\"]\n",
    "    )\n",
    "    \n",
    "    # 保存到CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"速度数据已保存至: {output_path}\")\n",
    "\n",
    "# 调用函数\n",
    "save_velocity_to_csv(velocity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_tran的形状为,torch.Size([1460, 3])\n",
      "out_joint的形状为,torch.Size([1677, 24, 3])\n",
      "out_vacc 样本数量: 9124\n",
      "out_vacc 样本数量: 1677\n",
      "第一个样本的加速度数据形状: torch.Size([1677, 3, 3])\n",
      "\n",
      "out_vrot 样本数量: 9124\n",
      "第一个样本的旋转数据形状: torch.Size([1677, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.wmx_tools import normalize_and_concat_X, normalize_and_concat_y\n",
    "import torch, os\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.TransPose.config import paths, joint_set, acc_scale, vel_scale\n",
    "\n",
    "print(f\"out_tran的形状为,{out_tran[1].shape}\")\n",
    "print(f\"out_joint的形状为,{out_joint[0].shape}\")\n",
    "# 检查列表长度和第一个元素的形状\n",
    "print(f\"out_vacc 样本数量: {len(out_vacc)}\")\n",
    "print(f\"out_vacc 样本数量: {out_vacc[0].shape[0]}\")\n",
    "if len(out_vacc) > 0:\n",
    "    print(f\"第一个样本的加速度数据形状: {out_vacc[0].shape}\")\n",
    "\n",
    "print(f\"\\nout_vrot 样本数量: {len(out_vrot)}\")\n",
    "if len(out_vrot) > 0:\n",
    "    print(f\"第一个样本的旋转数据形状: {out_vrot[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"X\": X_train, 'y': y_train},'./data/data_train_wmx100.pt')\n",
    "torch.save({\"X\": X_val, 'y': y_val},'./data/data_val_wmx100.pt')\n",
    "\n",
    "\n",
    "# # y: [temp_local_full_joint_position, temp_bone_length, temp_contact_probability, temp_velocity]\n",
    "# torch.save({\"X\": torch.cat([X_train[i].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(X_train))], dim = 0), \n",
    "#         'y': [torch.cat([y_train[i][0].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 3, 1, 2) for i in range(len(y_train))]), \n",
    "#             torch.cat([y_train[i][1].squeeze(1).repeat(y_train[i][0].shape[0], 1).unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_train))]), \n",
    "#             torch.cat([y_train[i][2].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_train))]), \n",
    "#             torch.cat([y_train[i][3].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_train))])]}, \n",
    "#             './data/data_train_wmx.pt')\n",
    "# torch.save({\"X\": torch.cat([X_val[i].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(X_val))], dim = 0), \n",
    "#         'y': [torch.cat([y_val[i][0].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 3, 1, 2) for i in range(len(y_val))]), \n",
    "#             torch.cat([y_val[i][1].squeeze(1).repeat(y_val[i][0].shape[0], 1).unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_val))]), \n",
    "#             torch.cat([y_val[i][2].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_val))]), \n",
    "#             torch.cat([y_val[i][3].unfold(dimension = 0, size = args.window_size, step = args.window_step).permute(0, 2, 1) for i in range(len(y_val))])]}, \n",
    "#             './data/data_val_wmx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.wmx_tools import create_args\n",
    "\n",
    "create_args(\"./configs/train_params_LSTM_Temp.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成网络config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.TransPose.config import paths, joint_set, acc_scale, vel_scale\n",
    "import yaml\n",
    "\n",
    "# 生成config\n",
    "with open(\"configs/models/LSTM_Small.yaml\", \"w\", encoding = \"utf-8\") as f:\n",
    "    temp_write = {}\n",
    "    temp_write[\"pose_net\"] = {\n",
    "        \"net_name\" : \"WMX_LSTMBlock\",\n",
    "        \"input_size\" : 36,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : joint_set.n_full * 3,\n",
    "        \"num_layers\" : 2,\n",
    "    }\n",
    "    temp_write[\"vel_net\"] = {\n",
    "        \"net_name\" : \"WMX_LSTMBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 3,\n",
    "        \"num_layers\" : 2,\n",
    "    }\n",
    "    temp_write[\"contact_net\"] = {\n",
    "        \"net_name\" : \"WMX_LSTMBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9 + 3,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 2,\n",
    "        \"num_layers\" : 2,\n",
    "    }\n",
    "    yaml.dump(temp_write, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.TransPose.config import paths, joint_set, acc_scale, vel_scale\n",
    "import yaml\n",
    "\n",
    "# 生成config\n",
    "with open(\"configs/models/TEA_Small.yaml\", \"w\", encoding = \"utf-8\") as f:\n",
    "    temp_write = {}\n",
    "    temp_write[\"pose_net\"] = {\n",
    "        \"net_name\" : \"WMX_TemporalExternalAttentionBlock\",\n",
    "        \"input_size\" : 36,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : joint_set.n_full * 3,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    temp_write[\"vel_net\"] = {\n",
    "        \"net_name\" : \"WMX_TemporalExternalAttentionBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 3,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    temp_write[\"contact_net\"] = {\n",
    "        \"net_name\" : \"WMX_TemporalExternalAttentionBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9 + 3,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 2,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    yaml.dump(temp_write, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.TransPose.config import paths, joint_set, acc_scale, vel_scale\n",
    "import yaml\n",
    "\n",
    "# 生成config\n",
    "with open(\"configs/models/SegNext_Small.yaml\", \"w\", encoding = \"utf-8\") as f:\n",
    "    temp_write = {}\n",
    "    temp_write[\"pose_net\"] = {\n",
    "        \"net_name\" : \"WMX_SegNextBlock\",\n",
    "        \"input_size\" : 36,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : joint_set.n_full * 3,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    temp_write[\"vel_net\"] = {\n",
    "        \"net_name\" : \"WMX_SegNextBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 3,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    temp_write[\"contact_net\"] = {\n",
    "        \"net_name\" : \"WMX_SegNextBlock\",\n",
    "        \"input_size\" : joint_set.n_full * 3 + 9 + 3,\n",
    "        \"hidden_size\" : 32,\n",
    "        \"output_size\" : 2,\n",
    "        \"num_layers\" : 4,\n",
    "    }\n",
    "    yaml.dump(temp_write, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
